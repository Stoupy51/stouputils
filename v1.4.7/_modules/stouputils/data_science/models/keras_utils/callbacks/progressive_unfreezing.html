<!DOCTYPE html>

<html lang="en" data-content_root="../../../../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing &#8212; stouputils</title>
    <link rel="stylesheet" type="text/css" href="../../../../../../_static/pygments.css?v=8e8a900e" />
    <link rel="stylesheet" type="text/css" href="../../../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../../../../_static/treeview.css?v=f8e9195c" />
    <link rel="stylesheet" type="text/css" href="../../../../../../_static/styles/breeze.css?v=d1c53b16" />
  <noscript>
    <style>
      .bz-js-only { display: none !important; }
    </style>
  </noscript>
    <script defer src="../../../../../../_static/documentation_options.js?v=eed287c7"></script>
    <script defer src="../../../../../../_static/doctools.js?v=9bcbadda"></script>
    <script defer src="../../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script defer src="../../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script defer src="../../../../../../_static/copybutton.js?v=18a8d5f5"></script>
    <script defer src="../../../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script defer src="../../../../../../_static/treeview.js?v=265ad9b8"></script>
    <script defer src="../../../../../../_static/scripts/breeze.js?v=8ef74970"></script>
  <script data-cfasync="false">
    const mode = localStorage.getItem("breeze-mode") || "auto";
    document.documentElement.dataset.mode = mode;
    if (mode === "auto") {
      const prefers = window.matchMedia("(prefers-color-scheme: dark)").matches ? "dark" : "light"
      document.documentElement.dataset.theme = prefers;
    } else {
      document.documentElement.dataset.theme = mode;
    }
  </script>
    <link rel="icon" href="https://avatars.githubusercontent.com/u/35665974"/>
    <link rel="index" title="Index" href="../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../search.html" /><meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head><body>
  
  <div class="bz-skip-to-content">
    <a href="#bz-main-content">Skip to main content</a>
  </div><header class="bz-header-main">
  <div class="bz-header-start"><a class="bz-header-brand" href="../../../../../../index.html"><img src="https://avatars.githubusercontent.com/u/35665974" alt="Site Logo" /><span>stouputils</span>
</a></div>
  <div class="bz-header-end"><div class="bz-search-button">
  <a
    href="../../../../../../search.html#q"
    aria-label="Search the docs"
    data-tooltip="Search the docs"
  >
    <svg
      class="sized"
      xmlns="http://www.w3.org/2000/svg"
      fill="none"
      viewBox="0 0 24 24"
      stroke-width="1.5"
      stroke="currentColor"
    >
      <path
        stroke-linecap="round"
        stroke-linejoin="round"
        d="m21 21-5.197-5.197m0 0A7.5 7.5 0 1 0 5.196 5.196a7.5 7.5 0 0 0 10.607 10.607Z"
      />
    </svg>
    <span>Search</span>
    <kbd>Ctrl+K</kbd>
  </a>
</div><div class="bz-theme-switcher">
  <button aria-label="Switch theme" data-tooltip="Switch theme">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="only-light" fill="currentColor">
      <path d="M8 12a4 4 0 1 1 0-8 4 4 0 0 1 0 8Zm0-1.5a2.5 2.5 0 1 0 0-5 2.5 2.5 0 0 0 0 5Zm5.657-8.157a.75.75 0 0 1 0 1.061l-1.061 1.06a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734l1.06-1.06a.75.75 0 0 1 1.06 0Zm-9.193 9.193a.75.75 0 0 1 0 1.06l-1.06 1.061a.75.75 0 1 1-1.061-1.06l1.06-1.061a.75.75 0 0 1 1.061 0ZM8 0a.75.75 0 0 1 .75.75v1.5a.75.75 0 0 1-1.5 0V.75A.75.75 0 0 1 8 0ZM3 8a.75.75 0 0 1-.75.75H.75a.75.75 0 0 1 0-1.5h1.5A.75.75 0 0 1 3 8Zm13 0a.75.75 0 0 1-.75.75h-1.5a.75.75 0 0 1 0-1.5h1.5A.75.75 0 0 1 16 8Zm-8 5a.75.75 0 0 1 .75.75v1.5a.75.75 0 0 1-1.5 0v-1.5A.75.75 0 0 1 8 13Zm3.536-1.464a.75.75 0 0 1 1.06 0l1.061 1.06a.75.75 0 0 1-1.06 1.061l-1.061-1.06a.75.75 0 0 1 0-1.061ZM2.343 2.343a.75.75 0 0 1 1.061 0l1.06 1.061a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-1.06-1.06a.75.75 0 0 1 0-1.06Z"></path>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="only-dark" fill="currentColor">
      <path d="M9.598 1.591a.749.749 0 0 1 .785-.175 7.001 7.001 0 1 1-8.967 8.967.75.75 0 0 1 .961-.96 5.5 5.5 0 0 0 7.046-7.046.75.75 0 0 1 .175-.786Zm1.616 1.945a7 7 0 0 1-7.678 7.678 5.499 5.499 0 1 0 7.678-7.678Z"></path>
    </svg>
  </button>
</div><div class="bz-external-links">
  <a
    href="https://github.com/Stoupy51/stouputils"
    aria-label="GitHub"
    data-tooltip="GitHub"
    target="_blank"
  >
    <svg
      stroke="currentColor"
      fill="currentColor"
      stroke-width="0"
      viewBox="0 0 16 16"
    >
      <path
        fill-rule="evenodd"
        d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"
      ></path>
    </svg>
  </a></div></div>
</header><nav class="bz-header-tabs" aria-label="Primary Navigation">
  <label
    class="bz-sidebar-primary-toggle"
    for="bz-sidebar-primary"
    role="button"
    tabindex="0"
  >
    <svg class="sized muted" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
      <path
        fill="none"
        stroke="currentColor"
        stroke-linecap="round"
        stroke-linejoin="round"
        stroke-width="2"
        d="M3.75 6.75h16.5M3.75 12H12m-8.25 5.25h12.5"
      />
    </svg>
  </label><ul><li class="toctree-l1"><a class="reference internal" href="../../../../../../modules/stouputils.html">stouputils package</a></li></ul><div class="bz-dropdown">
    <button aria-haspopup="true" aria-expanded="false">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
        <g
          fill="none"
          stroke="currentColor"
          stroke-linecap="round"
          stroke-linejoin="round"
          stroke-width="2"
        >
          <circle cx="12" cy="12" r="1" />
          <circle cx="19" cy="12" r="1" />
          <circle cx="5" cy="12" r="1" />
        </g>
      </svg>
    </button>
    <ul role="menu" aria-hidden="true"></ul>
  </div>
</nav><div class="bz-content"><main id="bz-main-content"><header class="bz-article-header">
  
  
    <nav class="bz-breadcrumb" aria-label="Breadcrumb">
  <ol>
    <li class="bz-breadcrumb-home">
      <a href="../../../../../../index.html">
        <svg
          xmlns="http://www.w3.org/2000/svg"
          viewBox="0 0 20 20"
          fill="currentColor"
        >
          <path
            fill-rule="evenodd"
            d="M9.293 2.293a1 1 0 0 1 1.414 0l7 7A1 1 0 0 1 17 11h-1v6a1 1 0 0 1-1 1h-2a1 1 0 0 1-1-1v-3a1 1 0 0 0-1-1H9a1 1 0 0 0-1 1v3a1 1 0 0 1-1 1H5a1 1 0 0 1-1-1v-6H3a1 1 0 0 1-.707-1.707l7-7Z"
            clip-rule="evenodd"
          />
        </svg>
      </a>
    </li><li class="bz-breadcrumb-parent">
      <a href="../../../../../index.html">Module code</a>
    </li><li class="bz-breadcrumb-current">
      <span>stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing</span>
    </li>
  </ol>
</nav>
  

  <label
    class="bz-sidebar-secondary-toggle"
    for="bz-sidebar-secondary"
    role="button"
    tabindex="0"
  >
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="sized muted">
      <path
        fill="none"
        stroke="currentColor"
        stroke-linecap="round"
        stroke-linejoin="round"
        stroke-width="2"
        d="M3.75 6.75H20.25 M11.25 12H20.25 M7.75 17.25H20.25"
      />
    </svg>
  </label>
</header><article class="bz-article-main" role="main">
  <h1>Source code for stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing</h1><div class="highlight"><pre>
<span></span>
<span class="c1"># pyright: reportMissingTypeStubs=false</span>

<span class="c1"># Imports</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">keras.callbacks</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callback</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">keras.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">keras.optimizers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optimizer</span>


<div class="viewcode-block" id="ProgressiveUnfreezing">
<a class="viewcode-back" href="../../../../../../modules/stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.html#stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.ProgressiveUnfreezing">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ProgressiveUnfreezing</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="w">	</span><span class="sd">&quot;&quot;&quot; Callback inspired by the Learning Rate Finder to progressively unfreeze model layers during training.</span>

<span class="sd">	Warning: This callback is not compatible with model.fit() as it modifies the trainable state of the model.</span>
<span class="sd">	Prefer doing your own training loop instead.</span>

<span class="sd">	This callback can operate in two modes:</span>
<span class="sd">	1. Start with all layers frozen and incrementally unfreeze them from 0% to 100% (progressive_freeze=False)</span>
<span class="sd">	2. Start with all layers unfrozen and incrementally freeze them from 100% to 0% (progressive_freeze=True)</span>
<span class="sd">	&quot;&quot;&quot;</span>

	<span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
		<span class="bp">self</span><span class="p">,</span>
		<span class="n">base_model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
		<span class="n">steps_per_epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
		<span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
		<span class="n">reset_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
		<span class="n">reset_optimizer_function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Optimizer</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
		<span class="n">update_per_epoch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
		<span class="n">update_interval</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
		<span class="n">progressive_freeze</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
	<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Initialize the progressive unfreezing callback.</span>

<span class="sd">		Args:</span>
<span class="sd">			base_model         (Model):   Base model to unfreeze.</span>
<span class="sd">			steps_per_epoch    (int):     Number of steps per epoch.</span>
<span class="sd">			epochs             (int):     Total number of epochs.</span>
<span class="sd">			reset_weights      (bool):    If True, reset weights after each unfreeze.</span>
<span class="sd">			reset_optimizer_function (Callable | None):</span>
<span class="sd">				If set, use this function to reset the optimizer every update_interval.</span>
<span class="sd">				The function should return a compiled optimizer, e.g. `lambda: model._get_optimizer(AdamW(...))`.</span>
<span class="sd">			update_per_epoch   (bool):    If True, unfreeze per epoch, else per batch.</span>
<span class="sd">			update_interval    (int):     Number of steps between each unfreeze to allow model to stabilize.</span>
<span class="sd">			progressive_freeze (bool):    If True, start with all layers unfrozen and progressively freeze them.</span>
<span class="sd">		&quot;&quot;&quot;</span>
		<span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">:</span> <span class="n">Model</span> <span class="o">=</span> <span class="n">base_model</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Base model to unfreeze. &quot;&quot;&quot;</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">:</span> <span class="n">Model</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Model to apply the progressive unfreezing to. &quot;&quot;&quot;</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">steps_per_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">steps_per_epoch</span><span class="p">)</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Number of steps per epoch. &quot;&quot;&quot;</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Total number of epochs. &quot;&quot;&quot;</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">reset_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">reset_weights</span><span class="p">)</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; If True, reset weights after each unfreeze. &quot;&quot;&quot;</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">reset_optimizer_function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Optimizer</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="n">reset_optimizer_function</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; If reset_weights is True and this is not None, use this function to get a new optimizer. &quot;&quot;&quot;</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">update_per_epoch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">update_per_epoch</span><span class="p">)</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; If True, unfreeze per epoch, else per batch. &quot;&quot;&quot;</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">update_interval</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">update_interval</span><span class="p">))</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Number of steps between each unfreeze to allow model to stabilize. &quot;&quot;&quot;</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">progressive_freeze</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">progressive_freeze</span><span class="p">)</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; If True, start with all layers unfrozen and progressively freeze them. &quot;&quot;&quot;</span>

		<span class="c1"># If updating per epoch, remove to self.epochs the update interval to allow the last step to train with 100% unfreeze</span>
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_per_epoch</span><span class="p">:</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_interval</span>

		<span class="c1"># Calculate total steps considering the update interval</span>
		<span class="n">total_steps_raw</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_per_epoch</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps_per_epoch</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">total_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">total_steps_raw</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_interval</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Total number of update steps (considering update_interval). &quot;&quot;&quot;</span>

		<span class="bp">self</span><span class="o">.</span><span class="n">fraction_unfrozen</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Fraction of layers unfrozen. &quot;&quot;&quot;</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Losses. &quot;&quot;&quot;</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">_all_layers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; All layers. &quot;&quot;&quot;</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">_initial_trainable</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Initial trainable states. &quot;&quot;&quot;</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">_initial_weights</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Initial weights of the model. &quot;&quot;&quot;</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">_last_update_step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Last step when layers were unfrozen. &quot;&quot;&quot;</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>

<div class="viewcode-block" id="ProgressiveUnfreezing.on_train_begin">
<a class="viewcode-back" href="../../../../../../modules/stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.html#stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.ProgressiveUnfreezing.on_train_begin">[docs]</a>
	<span class="k">def</span><span class="w"> </span><span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Set initial layer trainable states at the start of training and store initial states and weights.</span>

<span class="sd">		Args:</span>
<span class="sd">			logs (dict | None): Training logs.</span>
<span class="sd">		&quot;&quot;&quot;</span>
		<span class="c1"># Collect all layers from the model and preserve their original trainable states for potential restoration</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">_all_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="o">.</span><span class="n">layers</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">_initial_trainable</span> <span class="o">=</span> <span class="p">[</span><span class="nb">bool</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">trainable</span><span class="p">)</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_all_layers</span><span class="p">]</span>

		<span class="c1"># Store initial weights to reset after each unfreeze</span>
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_weights</span><span class="p">:</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">_initial_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>

		<span class="c1"># Set initial trainable state based on mode</span>
		<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_all_layers</span><span class="p">:</span>
			<span class="n">layer</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">progressive_freeze</span>  <span class="c1"># If progressive_freeze, start with all layers unfrozen</span></div>


<div class="viewcode-block" id="ProgressiveUnfreezing._update_layers">
<a class="viewcode-back" href="../../../../../../modules/stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.html#stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.ProgressiveUnfreezing._update_layers">[docs]</a>
	<span class="k">def</span><span class="w"> </span><span class="nf">_update_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Update layer trainable states based on the current step and mode.</span>
<span class="sd">		Reset weights after each update to prevent bias in the results.</span>

<span class="sd">		Args:</span>
<span class="sd">			step (int): Current training step.</span>
<span class="sd">		&quot;&quot;&quot;</span>
		<span class="c1"># Calculate the effective step considering the update interval</span>
		<span class="n">effective_step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">step</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_interval</span>

		<span class="c1"># Skip if we haven&#39;t reached the next update interval</span>
		<span class="k">if</span> <span class="n">effective_step</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_update_step</span><span class="p">:</span>
			<span class="k">return</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">_last_update_step</span> <span class="o">=</span> <span class="n">effective_step</span>

		<span class="c1"># Calculate the number of layers to unfreeze based on current effective step</span>
		<span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_all_layers</span><span class="p">)</span>

		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">progressive_freeze</span><span class="p">:</span>
			<span class="c1"># For progressive freezing, start at 1.0 (all unfrozen) and decrease to 0.0</span>
			<span class="n">fraction</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">effective_step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_steps</span><span class="p">)</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="c1"># For progressive unfreezing, start at 0.0 (all frozen) and increase to 1.0</span>
			<span class="n">fraction</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="n">effective_step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_steps</span><span class="p">)</span>

		<span class="n">n_unfreeze</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_layers</span> <span class="o">*</span> <span class="n">fraction</span><span class="p">)</span>  <span class="c1"># Number of layers to keep unfrozen</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">fraction_unfrozen</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fraction</span><span class="p">)</span>

		<span class="c1"># Set trainable state for each layer based on position</span>
		<span class="c1"># For both modes, we unfreeze from the top (output layers) to the bottom (input layers)</span>
		<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_all_layers</span><span class="p">):</span>
			<span class="n">layer</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="n">n_layers</span> <span class="o">-</span> <span class="n">n_unfreeze</span><span class="p">)</span>

		<span class="c1"># Reset weights to initial state to prevent bias and reset optimizer</span>
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_initial_weights</span><span class="p">)</span> <span class="c1"># pyright: ignore [reportUnknownMemberType]</span>
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_optimizer_function</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_optimizer_function</span><span class="p">()</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span> <span class="c1"># pyright: ignore [reportUnknownMemberType]</span></div>


<div class="viewcode-block" id="ProgressiveUnfreezing._track_loss">
<a class="viewcode-back" href="../../../../../../modules/stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.html#stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.ProgressiveUnfreezing._track_loss">[docs]</a>
	<span class="k">def</span><span class="w"> </span><span class="nf">_track_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Track the current loss.</span>

<span class="sd">		Args:</span>
<span class="sd">			logs (dict | None): Training logs containing loss information.</span>
<span class="sd">		&quot;&quot;&quot;</span>
		<span class="k">if</span> <span class="n">logs</span> <span class="ow">and</span> <span class="s2">&quot;loss&quot;</span> <span class="ow">in</span> <span class="n">logs</span><span class="p">:</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">])</span></div>


<div class="viewcode-block" id="ProgressiveUnfreezing.on_batch_begin">
<a class="viewcode-back" href="../../../../../../modules/stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.html#stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.ProgressiveUnfreezing.on_batch_begin">[docs]</a>
	<span class="k">def</span><span class="w"> </span><span class="nf">on_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Update layer trainable states at the start of each batch if not updating per epoch.</span>

<span class="sd">		Args:</span>
<span class="sd">			batch (int): Current batch index.</span>
<span class="sd">			logs (dict | None): Training logs.</span>
<span class="sd">		&quot;&quot;&quot;</span>
		<span class="c1"># Skip if we&#39;re updating per epoch instead of per batch</span>
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_per_epoch</span><span class="p">:</span>
			<span class="k">return</span>

		<span class="c1"># Calculate the current step across all epochs and update layers</span>
		<span class="n">step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps_per_epoch</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">batch</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">_update_layers</span><span class="p">(</span><span class="n">step</span><span class="p">)</span></div>


<div class="viewcode-block" id="ProgressiveUnfreezing.on_batch_end">
<a class="viewcode-back" href="../../../../../../modules/stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.html#stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.ProgressiveUnfreezing.on_batch_end">[docs]</a>
	<span class="k">def</span><span class="w"> </span><span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Track loss at the end of each batch if not updating per epoch.</span>

<span class="sd">		Args:</span>
<span class="sd">			batch (int): Current batch index.</span>
<span class="sd">			logs (dict | None): Training logs.</span>
<span class="sd">		&quot;&quot;&quot;</span>
		<span class="c1"># Skip if we&#39;re updating per epoch instead of per batch</span>
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_per_epoch</span><span class="p">:</span>
			<span class="k">return</span>

		<span class="c1"># Record the loss if update interval is reached</span>
		<span class="k">if</span> <span class="n">batch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">_track_loss</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span></div>


<div class="viewcode-block" id="ProgressiveUnfreezing.on_epoch_begin">
<a class="viewcode-back" href="../../../../../../modules/stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.html#stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.ProgressiveUnfreezing.on_epoch_begin">[docs]</a>
	<span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Update layer trainable states at the start of each epoch if updating per epoch.</span>

<span class="sd">		Args:</span>
<span class="sd">			epoch (int): Current epoch index.</span>
<span class="sd">			logs (dict | None): Training logs.</span>
<span class="sd">		&quot;&quot;&quot;</span>
		<span class="c1"># Skip if we&#39;re updating per batch instead of per epoch</span>
		<span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_per_epoch</span><span class="p">:</span>
			<span class="k">return</span>

		<span class="c1"># Update layers based on current epoch</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">_update_layers</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span></div>


<div class="viewcode-block" id="ProgressiveUnfreezing.on_epoch_end">
<a class="viewcode-back" href="../../../../../../modules/stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.html#stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.ProgressiveUnfreezing.on_epoch_end">[docs]</a>
	<span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Track loss at the end of each epoch if updating per epoch.</span>

<span class="sd">		Args:</span>
<span class="sd">			epoch (int): Current epoch index.</span>
<span class="sd">			logs (dict | None): Training logs.</span>
<span class="sd">		&quot;&quot;&quot;</span>
		<span class="c1"># Skip if we&#39;re updating per batch instead of per epoch</span>
		<span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_per_epoch</span><span class="p">:</span>
			<span class="k">return</span>

		<span class="c1"># Record the loss if update interval is reached</span>
		<span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">_track_loss</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span></div>


<div class="viewcode-block" id="ProgressiveUnfreezing.on_train_end">
<a class="viewcode-back" href="../../../../../../modules/stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.html#stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.ProgressiveUnfreezing.on_train_end">[docs]</a>
	<span class="k">def</span><span class="w"> </span><span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Restore original trainable states at the end of training.</span>

<span class="sd">		Args:</span>
<span class="sd">			logs (dict | None): Training logs.</span>
<span class="sd">		&quot;&quot;&quot;</span>
		<span class="c1"># Restore each layer&#39;s original trainable state</span>
		<span class="k">for</span> <span class="n">layer</span><span class="p">,</span> <span class="n">trainable</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_all_layers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_trainable</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
			<span class="n">layer</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="n">trainable</span></div>


<div class="viewcode-block" id="ProgressiveUnfreezing.get_results">
<a class="viewcode-back" href="../../../../../../modules/stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.html#stouputils.data_science.models.keras_utils.callbacks.progressive_unfreezing.ProgressiveUnfreezing.get_results">[docs]</a>
	<span class="k">def</span><span class="w"> </span><span class="nf">get_results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">multiply_by_100</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]]:</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot; Get the results of the progressive unfreezing from 0% to 100% even if progressive_freeze is True.</span>

<span class="sd">		Args:</span>
<span class="sd">			multiply_by_100 (bool): If True, multiply the fractions by 100 to get percentages.</span>

<span class="sd">		Returns:</span>
<span class="sd">			tuple[list[float], list[float]]: fractions of layers unfrozen, and losses.</span>
<span class="sd">		&quot;&quot;&quot;</span>
		<span class="n">fractions</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fraction_unfrozen</span>

		<span class="c1"># Reverse the order if progressive_freeze is True</span>
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">progressive_freeze</span><span class="p">:</span>
			<span class="n">fractions</span> <span class="o">=</span> <span class="n">fractions</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

		<span class="c1"># Multiply by 100 if requested</span>
		<span class="k">if</span> <span class="n">multiply_by_100</span><span class="p">:</span>
			<span class="n">fractions</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="o">*</span> <span class="mi">100</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">fractions</span><span class="p">]</span>

		<span class="c1"># Return the results</span>
		<span class="k">return</span> <span class="n">fractions</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">losses</span></div>
</div>


</pre></div>
</article><footer class="bz-article-footer">
  
  
    <nav class="bz-related-pages" aria-label="Related pages navigation"></nav>
  

</footer>

</main>
  </div><footer class="bz-footer">
  <div class="bz-footer-copyright"><p class="bz-copyright">© Copyright 2025, Stoupy</p><p>
    Made with
    
    <a href="https://www.sphinx-doc.org/">Sphinx</a> and
    
    <a href="https://github.com/aksiome/breeze">Breeze theme</a>.
  </p>
</div><div class="bz-external-links">
  <a
    href="https://github.com/Stoupy51/stouputils"
    aria-label="GitHub"
    data-tooltip="GitHub"
    target="_blank"
  >
    <svg
      stroke="currentColor"
      fill="currentColor"
      stroke-width="0"
      viewBox="0 0 16 16"
    >
      <path
        fill-rule="evenodd"
        d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"
      ></path>
    </svg>
  </a></div>
</footer><a href="#" class="bz-back-to-top">
    <svg class="sized" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2.5" stroke-linecap="round" stroke-linejoin="round">
      <path d="m5 12 7-7 7 7"/><path d="M12 19V5"/>
    </svg>
    <span>Back to top</span>
  </a>
  <label class="bz-overlay bz-overlay-primary" for="bz-sidebar-primary"></label>
  <label class="bz-overlay bz-overlay-secondary" for="bz-sidebar-secondary"></label>
  <input type="checkbox" name="bz-sidebar-primary" id="bz-sidebar-primary" aria-label="Toggle site navigation sidebar">
  <input type="checkbox" name="bz-sidebar-secondary" id="bz-sidebar-secondary" aria-label="Toggle table of contents sidebar">
  </body>
</html>